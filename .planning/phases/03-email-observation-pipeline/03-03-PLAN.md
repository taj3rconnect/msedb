---
phase: 03-email-observation-pipeline
plan: 03
type: execute
wave: 3
depends_on: ["03-02"]
files_modified:
  - backend/src/services/folderCache.ts
  - backend/src/services/deltaService.ts
  - backend/src/jobs/processors/deltaSync.ts
  - backend/src/jobs/queues.ts
autonomous: true
requirements: [OBSV-02]

must_haves:
  truths:
    - "Delta query runs every 15 minutes per mailbox per tracked folder"
    - "deltaLinks are stored in Redis keyed by delta:{mailboxId}:{folderId} with no TTL"
    - "Expired delta tokens (410 Gone) trigger a full sync by deleting the stored deltaLink"
    - "Delta query results are processed through the same event collector as webhook notifications"
    - "Folder ID-to-name mapping is cached in Redis for human-readable folder names in EmailEvents"
    - "Well-known folders (Inbox, SentItems, DeletedItems, Archive, Drafts, JunkEmail) are tracked"
  artifacts:
    - path: "backend/src/services/folderCache.ts"
      provides: "Folder ID-to-name cache in Redis, well-known folder discovery"
      exports: ["refreshFolderCache", "getFolderName", "getTrackedFolderIds", "WELL_KNOWN_FOLDERS"]
    - path: "backend/src/services/deltaService.ts"
      provides: "Delta query execution with pagination, deltaLink storage in Redis"
      exports: ["runDeltaSync", "runDeltaSyncForMailbox"]
    - path: "backend/src/jobs/processors/deltaSync.ts"
      provides: "BullMQ processor for scheduled and on-demand delta sync"
      exports: ["processDeltaSync"]
  key_links:
    - from: "backend/src/services/deltaService.ts"
      to: "backend/src/config/redis.ts"
      via: "getRedisClient for deltaLink storage"
      pattern: "getRedisClient|redis\\.get|redis\\.set|redis\\.del"
    - from: "backend/src/services/deltaService.ts"
      to: "backend/src/services/eventCollector.ts"
      via: "saveEmailEvent for delta query results"
      pattern: "saveEmailEvent|processChangeNotification"
    - from: "backend/src/services/deltaService.ts"
      to: "backend/src/services/graphClient.ts"
      via: "graphFetch for delta query API calls"
      pattern: "graphFetch"
    - from: "backend/src/jobs/processors/deltaSync.ts"
      to: "backend/src/services/deltaService.ts"
      via: "runDeltaSync call"
      pattern: "runDeltaSync"
    - from: "backend/src/services/deltaService.ts"
      to: "backend/src/services/metadataExtractor.ts"
      via: "extractMetadata for delta results"
      pattern: "extractMetadata"
---

<objective>
Build the delta query fallback system that catches events missed by webhooks. Every 15 minutes, iterate all connected mailboxes and their tracked folders, run Graph API delta queries to discover new/updated/deleted messages, and process them through the same event collector pipeline. Store deltaLinks in Redis for efficient incremental sync.

Purpose: Webhooks are best-effort -- Microsoft can drop notifications under load or when the endpoint is slow. Delta sync is the reliability guarantee that ensures no email event is ever permanently missed. Combined with the webhook pipeline from Plan 02, this creates a belt-and-suspenders observation system.

Output: folderCache.ts, deltaService.ts, deltaSync.ts processor
</objective>

<execution_context>
@./.claude/agents/gsd-executor.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/03-email-observation-pipeline/03-RESEARCH.md
@.planning/phases/03-email-observation-pipeline/03-01-SUMMARY.md
@.planning/phases/03-email-observation-pipeline/03-02-SUMMARY.md

@backend/src/services/graphClient.ts
@backend/src/services/eventCollector.ts
@backend/src/services/metadataExtractor.ts
@backend/src/utils/graph.ts
@backend/src/config/redis.ts
@backend/src/models/Mailbox.ts
@backend/src/models/EmailEvent.ts
@backend/src/auth/tokenManager.ts
@backend/src/jobs/queues.ts
@backend/src/jobs/processors/tokenRefresh.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Folder cache and delta sync service</name>
  <files>
    backend/src/services/folderCache.ts
    backend/src/services/deltaService.ts
  </files>
  <action>
    **1. Create `backend/src/services/folderCache.ts`:**

    Caches folder ID-to-name mappings in Redis so EmailEvents store human-readable folder names alongside opaque Graph folder IDs.

    - Import `getRedisClient` from `../config/redis.js`
    - Import `graphFetch` from `./graphClient.js`
    - Import `buildSelectParam` from `../utils/graph.js`
    - Import `logger`

    Constants:
    - `FOLDER_CACHE_PREFIX = 'folder'`
    - `FOLDER_CACHE_TTL = 24 * 60 * 60` (24 hours -- folders change rarely)
    - `WELL_KNOWN_FOLDERS = ['Inbox', 'SentItems', 'DeletedItems', 'Archive', 'Drafts', 'JunkEmail'] as const`

    Export `async function refreshFolderCache(mailboxEmail: string, accessToken: string): Promise<Map<string, string>>`:
    - Fetch all mail folders: `GET /users/${mailboxEmail}/mailFolders?$select=${buildSelectParam('mailFolder')}&$top=100`
    - Follow `@odata.nextLink` for pagination (mailboxes can have 100+ folders)
    - Build a Map of `folderId -> displayName`
    - Store each mapping in Redis: key = `${FOLDER_CACHE_PREFIX}:${mailboxEmail}:${folderId}`, value = `displayName`, with TTL of 24 hours
    - Also store a set of all folder IDs: key = `${FOLDER_CACHE_PREFIX}:${mailboxEmail}:all`, value = JSON array of folder IDs (with 24h TTL)
    - Return the Map
    - Log: "Refreshed folder cache for {mailboxEmail}: {count} folders"

    Export `async function getFolderName(mailboxEmail: string, folderId: string): Promise<string>`:
    - Look up from Redis: `${FOLDER_CACHE_PREFIX}:${mailboxEmail}:${folderId}`
    - If found, return it
    - If not found, return the folderId as-is (stale cache or new folder -- next refresh will pick it up)

    Export `async function getTrackedFolderIds(mailboxEmail: string, accessToken: string): Promise<string[]>`:
    - Try to get the cached folder list from Redis (`${FOLDER_CACHE_PREFIX}:${mailboxEmail}:all`)
    - If cache exists, parse and filter to well-known folders: for each well-known folder name, find its ID in the cache. Return those IDs.
    - If no cache, call `refreshFolderCache()` first, then filter
    - Return array of folder IDs for the well-known folders
    - For well-known folder resolution: call `GET /users/${mailboxEmail}/mailFolders/${wellKnownName}` for each well-known folder name to get its ID. Cache the mapping. This is more reliable than name-matching from the full folder list since Graph API supports well-known folder aliases directly.
    - Actually, the more efficient approach: call `GET /users/${mailboxEmail}/mailFolders/${wellKnownName}?$select=id,displayName` for each well-known folder. Cache the result. Some folders may not exist (Archive might not be enabled) -- handle 404 gracefully by skipping that folder.

    **2. Create `backend/src/services/deltaService.ts`:**

    Executes delta queries per folder, follows pagination, stores deltaLinks in Redis.

    - Import `graphFetch`, `GraphApiError` from `./graphClient.js`
    - Import `buildSelectParam` from `../utils/graph.js`
    - Import `getRedisClient` from `../config/redis.js`
    - Import `extractMetadata`, `type GraphMessage` from `./metadataExtractor.js`
    - Import `saveEmailEvent` from `./eventCollector.js`
    - Import `getFolderName`, `getTrackedFolderIds`, `refreshFolderCache` from `./folderCache.js`
    - Import `getAccessTokenForMailbox` from `../auth/tokenManager.js`
    - Import `Mailbox` from `../models/Mailbox.js`
    - Import `logger`

    Constants:
    - `DELTA_KEY_PREFIX = 'delta'`
    - `GRAPH_BASE = 'https://graph.microsoft.com/v1.0'` (import from graphClient)

    Internal helpers (not exported):

    `function deltaKey(mailboxId: string, folderId: string): string`:
    - Returns `${DELTA_KEY_PREFIX}:${mailboxId}:${folderId}`

    `async function getDeltaLink(mailboxId: string, folderId: string): Promise<string | null>`:
    - `return getRedisClient().get(deltaKey(mailboxId, folderId))`

    `async function setDeltaLink(mailboxId: string, folderId: string, link: string): Promise<void>`:
    - `await getRedisClient().set(deltaKey(mailboxId, folderId), link)`
    - NO TTL -- deltaLinks expire server-side (410 Gone)

    `async function deleteDeltaLink(mailboxId: string, folderId: string): Promise<void>`:
    - `await getRedisClient().del(deltaKey(mailboxId, folderId))`

    Export `async function runDeltaSync(mailboxId: string, mailboxEmail: string, folderId: string, accessToken: string, userId: string): Promise<{ created: number; updated: number; deleted: number; skipped: number }>`:
    - Get stored deltaLink from Redis
    - If exists, use it as the starting URL
    - If not, build initial URL: `${GRAPH_BASE}/users/${mailboxEmail}/mailFolders/${folderId}/messages/delta?$select=${buildSelectParam('message')}`
    - Get folder name via `getFolderName(mailboxEmail, folderId)` for storing in EmailEvents
    - Initialize counters: `{ created: 0, updated: 0, deleted: 0, skipped: 0 }`
    - Pagination loop:
      ```
      while (url) {
        try {
          response = await graphFetch(url, accessToken)
        } catch (err) {
          if (err instanceof GraphApiError && err.status === 410) {
            // Delta token expired -- delete and restart with full sync
            await deleteDeltaLink(mailboxId, folderId)
            logger.warn('Delta token expired, restarting full sync', { mailboxId, folderId })
            return runDeltaSync(mailboxId, mailboxEmail, folderId, accessToken, userId)
          }
          throw err
        }

        const data = await response.json()
        const messages: GraphMessage[] = data.value ?? []

        for (const msg of messages) {
          if (msg['@removed']) {
            // Deleted message
            const saved = await saveEmailEvent({
              userId, mailboxId, messageId: msg.id,
              eventType: 'deleted', timestamp: new Date(),
              // Try to copy metadata from prior events (same pattern as eventCollector)
            })
            saved ? deleted++ : skipped++
          } else {
            // Created or updated -- extract metadata and save
            const metadata = extractMetadata(msg)
            const saved = await saveEmailEvent({
              userId, mailboxId, ...metadata,
              eventType: 'arrived', // Delta sync treats all non-deleted as 'arrived'
              timestamp: metadata.receivedAt ?? new Date(),
              toFolder: folderName,
            })
            saved ? created++ : skipped++
          }
        }

        if (data['@odata.nextLink']) {
          url = data['@odata.nextLink']
        } else if (data['@odata.deltaLink']) {
          await setDeltaLink(mailboxId, folderId, data['@odata.deltaLink'])
          url = ''
        } else {
          url = ''
        }
      }
      ```
    - Return the counters
    - Important: `skipped` count represents duplicates caught by the compound unique index. This is EXPECTED and NORMAL -- delta sync will frequently see events already captured by webhooks.

    Export `async function runDeltaSyncForMailbox(mailboxId: string): Promise<void>`:
    - Find the Mailbox document to get `email` and `userId`
    - Get access token via `getAccessTokenForMailbox(mailboxId)`
    - Refresh folder cache for this mailbox (if stale -- the 24h TTL handles this)
    - Get tracked folder IDs via `getTrackedFolderIds(mailboxEmail, accessToken)`
    - For each tracked folder, call `runDeltaSync(mailboxId, mailboxEmail, folderId, accessToken, userId)`
    - Aggregate and log total counts across all folders
    - Update `Mailbox.lastSyncAt` to now

    Error handling:
    - If `getAccessTokenForMailbox` fails, log error and skip this mailbox (token refresh job handles reconnection)
    - If a single folder fails, log and continue to next folder (don't let one bad folder block all folders)
    - All errors logged with mailboxId, folderId context
  </action>
  <verify>
    1. `cd /home/admin/claude/MSEDB && docker compose exec backend npx tsc --noEmit` passes
    2. folderCache.ts exports refreshFolderCache, getFolderName, getTrackedFolderIds, WELL_KNOWN_FOLDERS
    3. deltaService.ts exports runDeltaSync, runDeltaSyncForMailbox
    4. Delta key format is `delta:{mailboxId}:{folderId}` with NO TTL
    5. 410 Gone triggers deltaLink deletion and full sync restart
    6. Delta results go through saveEmailEvent for deduplication
  </verify>
  <done>
    Folder cache stores ID-to-name mappings in Redis with 24h TTL. Delta sync service runs per-folder delta queries with pagination, stores deltaLinks in Redis without TTL, handles 410 Gone by resetting to full sync, and processes all results through the same saveEmailEvent deduplication pipeline.
  </done>
</task>

<task type="auto">
  <name>Task 2: Delta sync BullMQ processor</name>
  <files>
    backend/src/jobs/processors/deltaSync.ts
    backend/src/jobs/queues.ts
  </files>
  <action>
    **1. Create `backend/src/jobs/processors/deltaSync.ts`:**

    BullMQ processor for the delta-sync queue. Handles two job types:
    - Scheduled sync (every 15 minutes): runs delta sync for ALL connected mailboxes
    - On-demand sync (triggered by lifecycle events): runs delta sync for a specific mailbox

    - Import `type { Job }` from `'bullmq'`
    - Import `{ runDeltaSyncForMailbox }` from `'../../services/deltaService.js'`
    - Import `{ Mailbox }` from `'../../models/Mailbox.js'`
    - Import `logger`

    Export `async function processDeltaSync(job: Job): Promise<void>`:
    - Log job start with `{ jobId: job.id, jobName: job.name }`
    - Handle by `job.name`:

      **`'run-delta-sync'` (scheduled every 15m):**
      - Find all connected mailboxes: `Mailbox.find({ isConnected: true })`
      - For each mailbox, call `runDeltaSyncForMailbox(mailbox._id.toString())`
      - Wrap each mailbox call in try/catch -- log error and continue to next mailbox if one fails
      - Log completion with mailbox count: `{ synced, failed, total }`

      **`'lifecycle-delta-sync'` (from subscriptionService.handleLifecycleEvent):**
      - Extract `mailboxId` from `job.data`
      - Call `runDeltaSyncForMailbox(mailboxId)`
      - Log completion with mailboxId

      **Default:** Log warning for unknown job name, return without error

    **2. Update `backend/src/jobs/queues.ts`:**

    Wire the real delta-sync processor:
    - Import `{ processDeltaSync }` from `'./processors/deltaSync.js'`
    - Replace the placeholder processor for `'delta-sync'` with `processDeltaSync` in the processorMap
    - After this change, 4 of 6 queues have real processors: token-refresh, webhook-renewal, webhook-events, delta-sync. The remaining 2 (pattern-analysis, staging-processor) are for later phases.
  </action>
  <verify>
    1. `cd /home/admin/claude/MSEDB && docker compose exec backend npx tsc --noEmit` passes
    2. deltaSync.ts exports processDeltaSync
    3. queues.ts processorMap maps 'delta-sync' to processDeltaSync (not placeholder)
    4. processDeltaSync handles both 'run-delta-sync' and 'lifecycle-delta-sync' job names
    5. Only 2 placeholder processors remain: pattern-analysis, staging-processor
  </verify>
  <done>
    Delta sync processor runs for all connected mailboxes every 15 minutes (scheduled) and for specific mailboxes on-demand (lifecycle events). Wired as real BullMQ processor replacing placeholder. Four of six queues now have production processors.
  </done>
</task>

</tasks>

<verification>
- `docker compose exec backend npx tsc --noEmit` compiles cleanly
- deltaLinks stored in Redis with no TTL (verified by checking setDeltaLink has no TTL argument)
- 410 Gone response triggers full sync restart
- Delta results processed through saveEmailEvent (same deduplication as webhooks)
- Folder cache resolves well-known folders (Inbox, SentItems, DeletedItems, Archive, Drafts, JunkEmail)
- Scheduled delta sync iterates all connected mailboxes
- On-demand delta sync handles lifecycle-triggered jobs
- 4 of 6 BullMQ queues have real processors (token-refresh, webhook-renewal, webhook-events, delta-sync)
</verification>

<success_criteria>
- Delta query runs per-folder for each connected mailbox every 15 minutes
- deltaLinks persist in Redis across runs for efficient incremental sync
- Expired delta tokens (410 Gone) gracefully reset to full sync
- Folder ID-to-name cache enables human-readable folder names in EmailEvents
- All delta results deduplicated via the same compound unique index as webhook events
- On-demand delta sync triggered by lifecycle events catches missed notifications
</success_criteria>

<output>
After completion, create `.planning/phases/03-email-observation-pipeline/03-03-SUMMARY.md`
</output>
